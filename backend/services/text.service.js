const { logger } = require('../utils/logger');
const config = require('../config/config');
const ProcessingJob = require('../models/ProcessingJob');

// PLACEHOLDER: In production, this would handle actual text processing
// and interact with your database. Your friend will implement the real logic.

/**
 * Service layer for text processing operations
 */

/**
 * Simulate parallel text processing (Python-like simulation)
 * @param {string} text - Text to process
 * @param {Object} options - Processing options
 * @returns {Promise<Object>} Processing results
 */
const processTextParallel = async (text, options = {}) => {
  try {
    logger.info(`Text service: Starting parallel processing for ${text.length} characters`);
    
    const startTime = Date.now();
    
    // Configuration
    const batchSize = options.batchSize || config.processing.batchSize;
    const parallelWorkers = options.parallelWorkers || config.processing.parallelWorkers;
    
    // Split text into lines
    const lines = text.split('\n').filter(line => line.trim().length > 0);
    const totalLines = lines.length;
    
    logger.debug(`Text service: Split into ${totalLines} lines, using ${parallelWorkers} workers`);
    
    if (totalLines === 0) {
      return {
        success: false,
        error: 'No text content to process'
      };
    }
    
    // Split lines into chunks for parallel processing
    const chunkSize = Math.ceil(totalLines / parallelWorkers);
    const chunks = [];
    
    for (let i = 0; i < parallelWorkers; i++) {
      const start = i * chunkSize;
      const end = Math.min(start + chunkSize, totalLines);
      if (start < end) {
        chunks.push(lines.slice(start, end));
      }
    }
    
    // Simulate parallel processing
    const workerPromises = chunks.map(async (chunk, workerIndex) => {
      logger.debug(`Text service: Worker ${workerIndex + 1} processing ${chunk.length} lines`);
      
      // Simulate processing delay
      await new Promise(resolve => 
        setTimeout(resolve, Math.random() * 500 + 100)
      );
      
      // Simulate text analysis on each line
      const processedLines = chunk.map((line, lineIndex) => {
        // Simulate sentiment analysis (rule-based scoring)
        const sentimentScore = analyzeSentiment(line);
        
        // Simulate pattern finding
        const patterns = findPatterns(line);
        
        // Simulate keyword extraction
        const keywords = extractKeywords(line);
        
        return {
          original: line,
          sentiment: {
            score: sentimentScore,
            label: getSentimentLabel(sentimentScore)
          },
          patterns: patterns,
          keywords: keywords,
          metadata: {
            length: line.length,
            wordCount: line.split(/\s+/).length,
            worker: workerIndex + 1,
            lineNumber: (workerIndex * chunkSize) + lineIndex + 1
          }
        };
      });
      
      return {
        workerId: workerIndex + 1,
        linesProcessed: chunk.length,
        processed: processedLines
      };
    });
    
    // Wait for all workers to complete
    const workerResults = await Promise.all(workerPromises);
    
    // Combine results
    const allProcessedLines = workerResults.flatMap(r => r.processed);
    const totalLinesProcessed = workerResults.reduce((sum, r) => sum + r.linesProcessed, 0);
    
    // Calculate aggregate statistics
    const aggregateStats = calculateAggregateStats(allProcessedLines);
    
    const processingTime = Date.now() - startTime;
    
    logger.info(`Text service: Parallel processing completed in ${processingTime}ms`);
    
    return {
      success: true,
      results: {
        lines: allProcessedLines,
        statistics: {
          totalLines: totalLinesProcessed,
          processingTimeMs: processingTime,
          workersUsed: workerResults.length,
          linesPerSecond: totalLinesProcessed / (processingTime / 1000),
          ...aggregateStats
        },
        workerBreakdown: workerResults.map(r => ({
          workerId: r.workerId,
          linesProcessed: r.linesProcessed
        }))
      }
    };
  } catch (error) {
    logger.error(`Text service error in processTextParallel: ${error.message}`);
    return {
      success: false,
      error: error.message
    };
  }
};

/**
 * Simulate sentiment analysis (rule-based scoring)
 * @param {string} text - Text to analyze
 * @returns {number} Sentiment score from -100 to 100
 */
const analyzeSentiment = (text) => {
  // PLACEHOLDER: Replace with actual sentiment analysis logic
  // This is a simple rule-based simulation
  
  const positiveWords = ['good', 'great', 'excellent', 'happy', 'love', 'best', 'awesome', 'fantastic'];
  const negativeWords = ['bad', 'terrible', 'awful', 'hate', 'worst', 'disappointed', 'poor'];
  
  const lowerText = text.toLowerCase();
  let score = 0;
  
  // Check for positive words
  positiveWords.forEach(word => {
    if (lowerText.includes(word)) {
      score += 15;
    }
  });
  
  // Check for negative words
  negativeWords.forEach(word => {
    if (lowerText.includes(word)) {
      score -= 15;
    }
  });
  
  // Check for exclamation marks (excitement)
  const exclamationCount = (text.match(/!/g) || []).length;
  score += exclamationCount * 3;
  
  // Check for question marks (uncertainty)
  const questionCount = (text.match(/\?/g) || []).length;
  score -= questionCount * 2;
  
  // Add some random variation
  score += Math.floor(Math.random() * 20) - 10;
  
  // Clamp score between -100 and 100
  return Math.max(-100, Math.min(100, score));
};

/**
 * Simulate pattern finding
 * @param {string} text - Text to analyze
 * @returns {Array} Found patterns
 */
const findPatterns = (text) => {
  // PLACEHOLDER: Replace with actual pattern finding logic
  
  const patterns = [];
  
  // Check for email pattern
  const emailRegex = /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/;
  if (emailRegex.test(text)) {
    patterns.push('email_address');
  }
  
  // Check for URL pattern
  const urlRegex = /https?:\/\/[^\s]+/g;
  if (urlRegex.test(text)) {
    patterns.push('url');
  }
  
  // Check for date pattern
  const dateRegex = /\b\d{1,2}[\/\-]\d{1,2}[\/\-]\d{2,4}\b/;
  if (dateRegex.test(text)) {
    patterns.push('date');
  }
  
  // Check for phone number pattern
  const phoneRegex = /\b\d{3}[-.]?\d{3}[-.]?\d{4}\b/;
  if (phoneRegex.test(text)) {
    patterns.push('phone_number');
  }
  
  // Check for hashtags
  const hashtagRegex = /#\w+/g;
  const hashtags = text.match(hashtagRegex);
  if (hashtags && hashtags.length > 0) {
    patterns.push('hashtags');
  }
  
  return patterns;
};

/**
 * Simulate keyword extraction
 * @param {string} text - Text to extract keywords from
 * @returns {Array} Extracted keywords
 */
const extractKeywords = (text) => {
  // PLACEHOLDER: Replace with actual keyword extraction logic
  
  // Remove common stop words
  const stopWords = ['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'];
  
  // Split text into words, remove punctuation, convert to lowercase
  const words = text
    .toLowerCase()
    .replace(/[^\w\s]/g, ' ')
    .split(/\s+/)
    .filter(word => word.length > 2 && !stopWords.includes(word));
  
  // Count word frequency
  const wordCount = {};
  words.forEach(word => {
    wordCount[word] = (wordCount[word] || 0) + 1;
  });
  
  // Get top 5 most frequent words
  const sortedWords = Object.entries(wordCount)
    .sort((a, b) => b[1] - a[1])
    .slice(0, 5)
    .map(entry => entry[0]);
  
  return sortedWords;
};

/**
 * Calculate aggregate statistics from processed lines
 * @param {Array} processedLines - Processed line objects
 * @returns {Object} Aggregate statistics
 */
const calculateAggregateStats = (processedLines) => {
  if (processedLines.length === 0) {
    return {
      averageSentiment: 0,
      sentimentDistribution: { positive: 0, neutral: 0, negative: 0 },
      totalPatterns: 0,
      uniqueKeywords: 0,
      averageLength: 0
    };
  }
  
  const totalSentiment = processedLines.reduce((sum, line) => sum + line.sentiment.score, 0);
  const averageSentiment = totalSentiment / processedLines.length;
  
  // Count sentiment labels
  const sentimentCounts = { positive: 0, neutral: 0, negative: 0 };
  processedLines.forEach(line => {
    sentimentCounts[line.sentiment.label]++;
  });
  
  // Count total patterns found
  const totalPatterns = processedLines.reduce((sum, line) => sum + line.patterns.length, 0);
  
  // Count unique keywords
  const allKeywords = processedLines.flatMap(line => line.keywords);
  const uniqueKeywords = [...new Set(allKeywords)].length;
  
  // Calculate average text length
  const totalLength = processedLines.reduce((sum, line) => sum + line.metadata.length, 0);
  const averageLength = totalLength / processedLines.length;
  
  return {
    averageSentiment: parseFloat(averageSentiment.toFixed(2)),
    sentimentDistribution: {
      positive: sentimentCounts.positive,
      neutral: sentimentCounts.neutral,
      negative: sentimentCounts.negative,
      positivePercent: parseFloat(((sentimentCounts.positive / processedLines.length) * 100).toFixed(1)),
      neutralPercent: parseFloat(((sentimentCounts.neutral / processedLines.length) * 100).toFixed(1)),
      negativePercent: parseFloat(((sentimentCounts.negative / processedLines.length) * 100).toFixed(1))
    },
    totalPatterns,
    uniqueKeywords,
    averageLength: parseFloat(averageLength.toFixed(2))
  };
};

/**
 * Get sentiment label from score
 * @param {number} score - Sentiment score
 * @returns {string} Sentiment label
 */
const getSentimentLabel = (score) => {
  if (score > 20) return 'positive';
  if (score < -20) return 'negative';
  return 'neutral';
};

/**
 * Process batch of files
 * @param {Array} files - Array of files to process
 * @param {string} userId - User ID
 * @returns {Promise<Object>} Batch processing results
 */
const processBatch = async (files, userId) => {
  try {
    logger.info(`Text service: Starting batch processing for ${files.length} files, user: ${userId}`);
    
    const batchId = `batch_${Date.now()}_${userId}`;
    const startTime = Date.now();
    
    // Process each file in parallel
    const filePromises = files.map(async (file, index) => {
      try {
        // --- CONTENT EXTRACTION ---
        // In a real app, use fs.readFile(file.path, 'utf8') here.
        // For now, we use your simulation but capture it into a variable so we can save it.
        const fileContent = `This is simulated content for file ${index + 1}.\nIt contains words like good, bad, and excellent.\nThis text will be saved to the DB for searching.`;
        
        const result = await processTextParallel(fileContent);
        
        // --- SAVE TO DB ---
        if (result.success) {
            await saveProcessingResult(userId, {
                filename: file.originalname || `file_${index + 1}`,
                batchId: batchId, // Pass batchId
                content: fileContent, // PASS CONTENT HERE
                stats: result.results.statistics,
                results: result.results.lines,
                fileSize: file.size || fileContent.length
            });
        }

        return {
          fileIndex: index,
          filename: file.originalname || `file_${index + 1}`,
          success: result.success,
          result: result.success ? result.results : null,
          error: result.error || null,
          processingTime: Date.now() - startTime
        };
      } catch (error) {
        logger.error(`Text service: Error processing file ${index}: ${error.message}`);
        return {
          fileIndex: index,
          filename: file.originalname || `file_${index + 1}`,
          success: false,
          error: error.message
        };
      }
    });
    
    const fileResults = await Promise.all(filePromises);
    
    // ... (Keep the rest of the return logic exactly as is) ...
    const totalProcessingTime = Date.now() - startTime;
    const successfulFiles = fileResults.filter(r => r.success).length;
    const failedFiles = fileResults.filter(r => !r.success).length;
    
    const batchResult = {
      batchId,
      userId,
      totalFiles: files.length,
      successfulFiles,
      failedFiles,
      totalProcessingTime,
      results: fileResults,
      summary: {
        totalLinesProcessed: fileResults
          .filter(r => r.success && r.result)
          .reduce((sum, r) => sum + (r.result?.statistics?.totalLines || 0), 0),
        averageSentiment: calculateBatchAverageSentiment(fileResults)
      }
    };
    
    logger.info(`Text service: Batch processing completed in ${totalProcessingTime}ms`);
    
    return { success: true, batchResult };

  } catch (error) {
    logger.error(`Text service error in processBatch: ${error.message}`);
    return { success: false, error: error.message };
  }
};

/**
 * Calculate average sentiment for batch
 * @param {Array} fileResults - File processing results
 * @returns {number} Average sentiment
 */
const calculateBatchAverageSentiment = (fileResults) => {
  const successfulResults = fileResults.filter(r => r.success && r.result);
  
  if (successfulResults.length === 0) {
    return 0;
  }
  
  const totalSentiment = successfulResults.reduce((sum, r) => {
    return sum + (r.result?.statistics?.averageSentiment || 0);
  }, 0);
  
  return parseFloat((totalSentiment / successfulResults.length).toFixed(2));
};

/**
 * Save processing results to database (placeholder)
 * @param {string} userId - User ID
 * @param {Object} processingResult - Processing results
 * @returns {Promise<string>} Saved record ID
 */
const saveProcessingResult = async (userId, data) => {
  try {
    const job = new ProcessingJob({
      userId,
      batchId: data.batchId, // Save the batch ID
      originalFilename: data.filename,
      filename: data.filename, 
      status: 'completed',
      // --- SAVE THE CONTENT ---
      textContent: data.content, 
      // ------------------------
      totalLines: data.stats.totalLines,
      averageSentiment: data.stats.averageSentiment,
      fileSize: data.fileSize,
      results: data.results,
      sentimentDistribution: data.stats.sentimentDistribution,
      processingTimeMs: data.stats.processingTimeMs,
      completedAt: new Date()
    });

    await job.save();
    logger.debug(`Text service: Saved processing job ${job._id} for user ${userId}`);
    return job._id;
  } catch (error) {
    logger.error(`Text service error in saveProcessingResult: ${error.message}`);
    // Don't throw to avoid crashing the whole batch
    return null; 
  }
};

/**
 * Get processing job status
 * @param {string} jobId - Job ID
 * @returns {Promise<Object>} Job status
 */
const getJobStatus = async (jobId) => {
  try {
    // PLACEHOLDER: Replace with actual database query
    // Your friend will implement this
    
    // Simulated status
    const statuses = ['pending', 'processing', 'completed', 'failed'];
    const randomStatus = statuses[Math.floor(Math.random() * statuses.length)];
    
    return {
      jobId,
      status: randomStatus,
      progress: randomStatus === 'processing' ? Math.floor(Math.random() * 100) : 
               randomStatus === 'completed' ? 100 : 0,
      estimatedCompletion: randomStatus === 'processing' ? 
        new Date(Date.now() + 30000).toISOString() : null
    };
  } catch (error) {
    logger.error(`Text service error in getJobStatus: ${error.message}`);
    throw new Error('Failed to get job status');
  }
};

module.exports = {
  processTextParallel,
  processBatch,
  saveProcessingResult,
  getJobStatus,
  analyzeSentiment,
  findPatterns,
  extractKeywords
};